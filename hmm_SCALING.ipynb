{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prova con scaling factor ( da rvidere)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# We need an algorithm to perform belief propagation on our hmm\n",
    "def forward_HMM(A, B, pi, observed):\n",
    "    \"\"\"\n",
    "    A: transition\n",
    "    B: emission\n",
    "    pi: initial\n",
    "    n_nodes: number of nodes in the chain\n",
    "    observed: list containing observed ones.\n",
    "    \"\"\"\n",
    "    n_nodes = len(observed)\n",
    "    n_states = A.shape[0]\n",
    "    alpha = np.zeros((n_nodes, n_states))\n",
    "    c = np.zeros(n_nodes)\n",
    "\n",
    "    for j in range(n_states):\n",
    "        alpha[0, j] = pi[j] * B[j, observed[0]]\n",
    "\n",
    "    c[0] = 1.0 / np.sum(alpha[0])\n",
    "\n",
    "    for i in range(1, n_nodes):\n",
    "        for j in range(n_states):\n",
    "            for k in range(n_states):\n",
    "                alpha[i, j] = (\n",
    "                    alpha[i, j] + A[k, j] * B[j, observed[i]] * alpha[i - 1, k]\n",
    "                )\n",
    "\n",
    "            c[i] = 1.0 / np.sum(alpha[i])\n",
    "\n",
    "    return alpha, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need an algorithm to perform belief propagation on our hmm\n",
    "def backward_HMM(A, B, observed, c):\n",
    "    \"\"\"\n",
    "    A: transition\n",
    "    B: emission\n",
    "    n_nodes: number of nodes in the chain\n",
    "    observed: list containing observed ones.\n",
    "    \"\"\"\n",
    "    n_nodes = len(observed)\n",
    "    n_states = A.shape[0]\n",
    "    beta = np.zeros((n_nodes - 1, n_states))\n",
    "\n",
    "    for j in range(n_states):\n",
    "        for k in range(n_states):\n",
    "            beta[-1, j] = (beta[-1, j] + A[j, k] * B[k, observed[n_nodes - 1]]) * c[-1]\n",
    "\n",
    "    for i in range(n_nodes - 3, -1, -1):\n",
    "        for j in range(n_states):\n",
    "            for k in range(n_states):\n",
    "                beta[i, j] = (\n",
    "                    beta[i, j] + A[j, k] * B[k, observed[i + 1]] * beta[i + 1, k]\n",
    "                ) * c[i]\n",
    "\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_conditional(alpha, beta, i):\n",
    "    \"\"\"\n",
    "    alpha: list containing forward messages\n",
    "    beta: list containing backward messages\n",
    "    i : hidden element for which you want the conditional on the observed variables (i = 1, ..., M)\n",
    "    \"\"\"\n",
    "    if i == 0:\n",
    "        raise ValueError(\"no zio serve il numero di variabile\")\n",
    "\n",
    "    if i == alpha.shape[0]:\n",
    "        return alpha[i - 1] / np.sum(alpha[i - 1])\n",
    "\n",
    "    gamma = alpha[i - 1] * beta[i - 1]\n",
    "    gamma = gamma / np.sum(gamma)\n",
    "\n",
    "    return gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_all_conditional(alpha, beta):\n",
    "    \"\"\"\n",
    "    alpha: list containing forward messages\n",
    "    beta: list containing backward messages\n",
    "    \"\"\"\n",
    "    n_nodes = alpha.shape[0]\n",
    "    n_states = alpha.shape[1]\n",
    "\n",
    "    gamma = np.zeros((n_nodes, n_states))\n",
    "\n",
    "    gamma[n_nodes - 1] = alpha[n_nodes - 1] / np.sum(alpha[n_nodes - 1])\n",
    "\n",
    "    for i in range(n_nodes - 1):\n",
    "        gamma[i] = alpha[i] * beta[i] / np.sum(alpha[i] * beta[i])\n",
    "\n",
    "    return gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_row_by_sum(matrix):\n",
    "    row_sums = np.sum(matrix, axis=1)  # Calculate the sum of each row\n",
    "    divided_matrix = (\n",
    "        matrix / row_sums[:, np.newaxis]\n",
    "    )  # Divide each element by the corresponding row sum\n",
    "    return divided_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_B(gamma, observed):\n",
    "    # n_nodes = gamma.shape[0]\n",
    "    n_states = gamma.shape[1]\n",
    "\n",
    "    B = np.zeros((n_states, n_states))\n",
    "\n",
    "    for i in range(n_states):\n",
    "        for j in range(n_states):\n",
    "            for k in range(len(observed)):\n",
    "                if observed[k] == j:\n",
    "                    B[i, j] += gamma[k, i]\n",
    "\n",
    "    return divide_row_by_sum(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Baum_Welch(A, B_start, pi, observed, maxIter=100):\n",
    "    B = np.copy(B_start)\n",
    "    for it in range(maxIter):\n",
    "        alpha, c = forward_HMM(A, B, pi, observed)\n",
    "        beta = backward_HMM(A, B, observed, c)\n",
    "        gamma = compute_all_conditional(alpha, beta)\n",
    "        B = update_B(gamma, observed)\n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt version of scaling\n",
    "\n",
    "\n",
    "def forward_HMM_scaled(A, B, pi, observed):\n",
    "    n_nodes = len(observed)\n",
    "    n_states = A.shape[0]\n",
    "    alpha = np.zeros((n_nodes, n_states))\n",
    "    scaling_factors = np.zeros(n_nodes)\n",
    "\n",
    "    # Initialization\n",
    "    scaling_factors[0] = 1.0 / np.sum(pi * B[:, observed[0]])\n",
    "    alpha[0, :] = pi * B[:, observed[0]] * scaling_factors[0]\n",
    "\n",
    "    # Induction\n",
    "    for i in range(1, n_nodes):\n",
    "        scaling_factors[i] = 1.0 / np.sum(A @ (alpha[i - 1, :] * B[:, observed[i - 1]]))\n",
    "        alpha[i, :] = (\n",
    "            A\n",
    "            @ (alpha[i - 1, :] * B[:, observed[i - 1]])\n",
    "            * B[:, observed[i]]\n",
    "            * scaling_factors[i]\n",
    "        )\n",
    "\n",
    "    return alpha, scaling_factors\n",
    "\n",
    "\n",
    "def backward_HMM_scaled(A, B, observed, scaling_factors):\n",
    "    n_nodes = len(observed)\n",
    "    n_states = A.shape[0]\n",
    "    beta = np.zeros((n_nodes, n_states))\n",
    "\n",
    "    # Initialization\n",
    "    beta[n_nodes - 1, :] = scaling_factors[n_nodes - 1]\n",
    "\n",
    "    # Induction\n",
    "    for i in range(n_nodes - 2, -1, -1):\n",
    "        beta[i, :] = A.T @ (B[:, observed[i + 1]] * beta[i + 1, :]) * scaling_factors[i]\n",
    "\n",
    "    return beta\n",
    "\n",
    "\n",
    "def Baum_Welch_scaled(A, B_start, pi, observed, maxIter=100):\n",
    "    B = np.copy(B_start)\n",
    "    for it in range(maxIter):\n",
    "        alpha, scaling_factors = forward_HMM_scaled(A, B, pi, observed)\n",
    "        beta = backward_HMM_scaled(A, B, observed, scaling_factors)\n",
    "        gamma = compute_all_conditional(alpha, beta)\n",
    "        B = update_B(gamma, observed)\n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# questo non so cosa sia\n",
    "\n",
    "\n",
    "def baum_welch_gpt_not_scaling(A, B_start, pi, observed, maxiter):\n",
    "    N = A.shape[0]  # Number of states\n",
    "    M = A.shape[1]  # Number of possible emissions\n",
    "    T = len(observed)  # Length of observed chain\n",
    "\n",
    "    B = B_start.copy()  # Make a copy of initial emission probabilities\n",
    "\n",
    "    for _ in range(maxiter):\n",
    "        # Forward-Backward algorithm (Expectation step)\n",
    "        alpha = np.zeros((T, N))\n",
    "        beta = np.zeros((T, N))\n",
    "        c = np.zeros(T)\n",
    "\n",
    "        # Forward pass\n",
    "        alpha[0] = pi * B[:, observed[0]]\n",
    "        c[0] = 1.0 / np.sum(alpha[0])\n",
    "        alpha[0] *= c[0]\n",
    "        for t in range(1, T):\n",
    "            alpha[t] = np.dot(alpha[t - 1], A) * B[:, observed[t]]\n",
    "            c[t] = 1.0 / np.sum(alpha[t])\n",
    "            alpha[t] *= c[t]\n",
    "\n",
    "        # Backward pass\n",
    "        beta[T - 1] = 1\n",
    "        beta[T - 1] *= c[T - 1]\n",
    "        for t in range(T - 2, -1, -1):\n",
    "            beta[t] = np.dot(A, beta[t + 1] * B[:, observed[t + 1]])\n",
    "            beta[t] *= c[t]\n",
    "\n",
    "        # Compute gamma and xi matrices\n",
    "        gamma = alpha * beta\n",
    "        xi = np.zeros((T - 1, N, N))\n",
    "        for t in range(T - 1):\n",
    "            xi[t] = (\n",
    "                alpha[t][:, np.newaxis] * A * B[:, observed[t + 1]] * beta[t + 1]\n",
    "            ) * c[t]\n",
    "\n",
    "        # Maximization step\n",
    "        B_new = np.zeros((N, M))\n",
    "        for i in range(N):\n",
    "            for j in range(M):\n",
    "                B_new[i, j] = np.sum(gamma[:, i] * (observed == j)) / np.sum(\n",
    "                    gamma[:, i]\n",
    "                )\n",
    "\n",
    "        # Check for convergence\n",
    "        if np.allclose(B, B_new):\n",
    "            break\n",
    "\n",
    "        B = B_new\n",
    "\n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def baum_welch_gpt_scaling(A, B_start, pi, observed, maxiter=100):\n",
    "    N = A.shape[0]  # Number of states\n",
    "    M = A.shape[1]  # Number of possible emissions\n",
    "    T = len(observed)  # Length of observed chain\n",
    "\n",
    "    B = B_start.copy()  # Make a copy of initial emission probabilities\n",
    "\n",
    "    for _ in range(maxiter):\n",
    "        # Forward-Backward algorithm (Expectation step)\n",
    "        alpha = np.zeros((T, N))\n",
    "        beta = np.zeros((T, N))\n",
    "        c = np.zeros(T)\n",
    "\n",
    "        # Forward pass\n",
    "        alpha[0] = pi * B[:, observed[0]]\n",
    "        c[0] = 1.0 / np.sum(alpha[0])\n",
    "        alpha[0] *= c[0]\n",
    "        for t in range(1, T):\n",
    "            alpha[t] = np.dot(alpha[t - 1], A) * B[:, observed[t]]\n",
    "            c[t] = 1.0 / np.sum(alpha[t])\n",
    "            alpha[t] *= c[t]\n",
    "\n",
    "        # Backward pass\n",
    "        beta[T - 1] = 1\n",
    "        beta[T - 1] *= c[T - 1]\n",
    "        for t in range(T - 2, -1, -1):\n",
    "            beta[t] = np.dot(A, beta[t + 1] * B[:, observed[t + 1]])\n",
    "            beta[t] *= c[t]\n",
    "\n",
    "        # Scaling factors\n",
    "        scale = np.cumprod(c)\n",
    "        alpha *= scale[:, np.newaxis]\n",
    "        beta *= scale[:, np.newaxis]\n",
    "\n",
    "        # Compute gamma and xi matrices\n",
    "        gamma = alpha * beta\n",
    "        xi = np.zeros((T - 1, N, N))\n",
    "        for t in range(T - 1):\n",
    "            xi[t] = alpha[t][:, np.newaxis] * A * B[:, observed[t + 1]] * beta[t + 1]\n",
    "\n",
    "        # Maximization step\n",
    "        B_new = np.zeros((N, M))\n",
    "        for i in range(N):\n",
    "            for j in range(M):\n",
    "                B_new[i, j] = np.sum(gamma[:, i] * (observed == j)) / np.sum(\n",
    "                    gamma[:, i]\n",
    "                )\n",
    "\n",
    "        # Check for convergence\n",
    "        if np.allclose(B, B_new):\n",
    "            break\n",
    "\n",
    "        B = B_new\n",
    "\n",
    "    return B"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[0.6, 0.4], [0.3, 0.7]])\n",
    "B = np.array([[0.5, 0.5], [0.1, 0.9]])\n",
    "pi = np.array([0.2, 0.8])\n",
    "observed = np.array([1, 0, 1])\n",
    "B_start = np.zeros((2, 2)) + 0.5\n",
    "\n",
    "alpha, c = forward_HMM(A, B, pi, observed)\n",
    "beta = backward_HMM(A, B, observed, c)\n",
    "gamma = compute_all_conditional(alpha, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.61345426, 0.38654574],\n",
       "       [0.14035149, 0.85964851]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Baum_Welch(A, B_start, pi, observed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.52062804, 0.47937196],\n",
       "       [0.36155231, 0.63844769]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baum_welch_gpt_not_scaling(A, B_start, pi, observed, maxiter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m2/r059lv3n7nq9x6gh78v25xk80000gn/T/ipykernel_96935/1419852217.py:39: RuntimeWarning: overflow encountered in multiply\n",
      "  gamma = alpha * beta\n",
      "/var/folders/m2/r059lv3n7nq9x6gh78v25xk80000gn/T/ipykernel_96935/1419852217.py:48: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  B_new[i, j] = np.sum(gamma[:, i] * (observed == j)) / np.sum(\n",
      "/var/folders/m2/r059lv3n7nq9x6gh78v25xk80000gn/T/ipykernel_96935/1419852217.py:48: RuntimeWarning: invalid value encountered in multiply\n",
      "  B_new[i, j] = np.sum(gamma[:, i] * (observed == j)) / np.sum(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[nan, nan],\n",
       "       [nan, nan]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baum_welch_gpt_scaling(A, B_start, pi, observed, maxiter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = [0.5, 0.5]\n",
    "N = 10000\n",
    "\n",
    "A = np.array([[0.2, 0.8], [0.6, 0.4]])\n",
    "\n",
    "chain = np.zeros(N)\n",
    "chain[0] = np.random.binomial(1, 0.5)\n",
    "for i in range(1, N):\n",
    "    if chain[i - 1] == 0:\n",
    "        chain[i] = np.random.binomial(1, 0.8)\n",
    "    else:\n",
    "        chain[i] = np.random.binomial(1, 0.4)\n",
    "\n",
    "chain = chain.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_true = np.array([[0.8, 0.2], [0.1, 0.9]])\n",
    "\n",
    "viewed_chain = np.zeros(N)\n",
    "for i in range(N):\n",
    "    if chain[i] == 0:\n",
    "        viewed_chain[i] = np.random.binomial(1, B[0, 1])\n",
    "    else:\n",
    "        viewed_chain[i] = np.random.binomial(1, B[1, 1])\n",
    "\n",
    "viewed_chain = viewed_chain.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_start = np.zeros((2, 2)) + 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m2/r059lv3n7nq9x6gh78v25xk80000gn/T/ipykernel_96935/2378624948.py:30: RuntimeWarning: overflow encountered in double_scalars\n",
      "  c[i] = 1.0 / np.sum(alpha[i])\n",
      "/var/folders/m2/r059lv3n7nq9x6gh78v25xk80000gn/T/ipykernel_96935/2378624948.py:30: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  c[i] = 1.0 / np.sum(alpha[i])\n",
      "/var/folders/m2/r059lv3n7nq9x6gh78v25xk80000gn/T/ipykernel_96935/1766464708.py:11: RuntimeWarning: invalid value encountered in divide\n",
      "  gamma[n_nodes - 1] = alpha[n_nodes - 1] / np.sum(alpha[n_nodes - 1])\n",
      "/var/folders/m2/r059lv3n7nq9x6gh78v25xk80000gn/T/ipykernel_96935/1766464708.py:14: RuntimeWarning: invalid value encountered in divide\n",
      "  gamma[i] = alpha[i] * beta[i] / np.sum(alpha[i] * beta[i])\n",
      "/var/folders/m2/r059lv3n7nq9x6gh78v25xk80000gn/T/ipykernel_96935/1766464708.py:14: RuntimeWarning: invalid value encountered in multiply\n",
      "  gamma[i] = alpha[i] * beta[i] / np.sum(alpha[i] * beta[i])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Baum_Welch(A, B_start, pi, observed\u001b[39m=\u001b[39;49mviewed_chain, maxIter\u001b[39m=\u001b[39;49m\u001b[39m10000\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m, in \u001b[0;36mBaum_Welch\u001b[0;34m(A, B_start, pi, observed, maxIter)\u001b[0m\n\u001b[1;32m      2\u001b[0m B \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mcopy(B_start)\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m it \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(maxIter):\n\u001b[0;32m----> 4\u001b[0m     alpha, c \u001b[39m=\u001b[39m forward_HMM(A, B, pi, observed)\n\u001b[1;32m      5\u001b[0m     beta \u001b[39m=\u001b[39m backward_HMM(A, B, observed, c)\n\u001b[1;32m      6\u001b[0m     gamma \u001b[39m=\u001b[39m compute_all_conditional(alpha, beta)\n",
      "Cell \u001b[0;32mIn[2], line 26\u001b[0m, in \u001b[0;36mforward_HMM\u001b[0;34m(A, B, pi, observed)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_states):\n\u001b[1;32m     25\u001b[0m         \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_states):\n\u001b[0;32m---> 26\u001b[0m             alpha[i, j] \u001b[39m=\u001b[39m (\n\u001b[1;32m     27\u001b[0m                 alpha[i, j] \u001b[39m+\u001b[39m A[k, j] \u001b[39m*\u001b[39m B[j, observed[i]] \u001b[39m*\u001b[39m alpha[i \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m, k]\n\u001b[1;32m     28\u001b[0m             )\n\u001b[1;32m     30\u001b[0m         c[i] \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m np\u001b[39m.\u001b[39msum(alpha[i])\n\u001b[1;32m     32\u001b[0m \u001b[39mreturn\u001b[39;00m alpha, c\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Baum_Welch(A, B_start, pi, observed=viewed_chain, maxIter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01750132, 0.98249868],\n",
       "       [0.42631791, 0.57368209]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Baum_Welch_scaled(A, B_start, pi, observed=viewed_chain, maxIter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11243579, 0.88756421],\n",
       "       [0.54824586, 0.45175414]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baum_welch(A, B_start, pi, observed=viewed_chain, maxiter=1000000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cancella sotto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# We need an algorithm to perform belief propagation on our hmm\n",
    "def forward_HMM(A, B, pi, observed):\n",
    "    \"\"\"\n",
    "    A: transition\n",
    "    B: emission\n",
    "    pi: initial\n",
    "    observed: list containing observed ones.\n",
    "    \"\"\"\n",
    "    n_nodes = len(observed)\n",
    "    n_states = A.shape[0]\n",
    "    alpha = np.zeros((n_nodes, n_states))\n",
    "    scaling_factors = np.zeros(n_nodes)\n",
    "\n",
    "    # Initialization\n",
    "    scaling_factors[0] = 1.0 / np.sum(pi * B[:, observed[0]])\n",
    "    alpha[0, :] = scaling_factors[0] * pi * B[:, observed[0]]\n",
    "\n",
    "    # Induction\n",
    "    for i in range(1, n_nodes):\n",
    "        scaling_factors[i] = 1.0 / np.sum(\n",
    "            alpha[i - 1, :] * A[:, :].T * B[:, observed[i]]\n",
    "        )\n",
    "        alpha[i, :] = (\n",
    "            scaling_factors[i] * (alpha[i - 1, :] @ A[:, :]) * B[:, observed[i]]\n",
    "        )\n",
    "\n",
    "    return alpha, scaling_factors\n",
    "\n",
    "\n",
    "# We need an algorithm to perform belief propagation on our hmm\n",
    "def backward_HMM(A, B, observed, scaling_factors):\n",
    "    \"\"\"\n",
    "    A: transition\n",
    "    B: emission\n",
    "    observed: list containing observed ones.\n",
    "    scaling_factors: scaling factors computed during forward pass\n",
    "    \"\"\"\n",
    "    n_nodes = len(observed)\n",
    "    n_states = A.shape[0]\n",
    "    beta = np.zeros((n_nodes - 1, n_states))\n",
    "\n",
    "    # Initialization\n",
    "    beta[-1, :] = scaling_factors[-1] * np.ones(n_states)\n",
    "\n",
    "    # Induction\n",
    "    for i in range(n_nodes - 3, -1, -1):\n",
    "        beta[i, :] = scaling_factors[i + 1] * (\n",
    "            beta[i + 1, :] * B[:, observed[i + 1]] @ A[:, :].T\n",
    "        )\n",
    "\n",
    "    return beta\n",
    "\n",
    "\n",
    "def compute_all_conditional(alpha, beta, scaling_factors):\n",
    "    \"\"\"\n",
    "    alpha: forward messages\n",
    "    beta: backward messages\n",
    "    scaling_factors: scaling factors computed during forward pass\n",
    "    \"\"\"\n",
    "    n_nodes = alpha.shape[0]\n",
    "    n_states = alpha.shape[1]\n",
    "\n",
    "    gamma = np.zeros((n_nodes, n_states))\n",
    "\n",
    "    gamma[-1, :] = alpha[-1, :] / np.sum(alpha[-1, :])\n",
    "\n",
    "    for i in range(n_nodes - 1):\n",
    "        gamma[i, :] = (alpha[i, :] * beta[i, :]) / np.sum(alpha[i, :] * beta[i, :])\n",
    "        gamma[i, :] /= scaling_factors[i]\n",
    "\n",
    "    return gamma\n",
    "\n",
    "\n",
    "def divide_row_by_sum(matrix):\n",
    "    row_sums = np.sum(matrix, axis=1)  # Calculate the sum of each row\n",
    "    divided_matrix = (\n",
    "        matrix / row_sums[:, np.newaxis]\n",
    "    )  # Divide each element by the corresponding row sum\n",
    "    return divided_matrix\n",
    "\n",
    "\n",
    "def update_B(gamma, observed):\n",
    "    n_states = gamma.shape[1]\n",
    "    B = np.zeros((n_states, n_states))\n",
    "\n",
    "    for i in range(n_states):\n",
    "        for j in range(n_states):\n",
    "            for k in range(len(observed)):\n",
    "                if observed[k] == j:\n",
    "                    B[i, j] += gamma[k, i]\n",
    "\n",
    "    return divide_row_by_sum(B)\n",
    "\n",
    "\n",
    "def Baum_Welch(A, B_start, pi, observed, maxIter=100):\n",
    "    B = np.copy(B_start)\n",
    "    for it in range(maxIter):\n",
    "        alpha, scaling_factors = forward_HMM(A, B, pi, observed)\n",
    "        beta = backward_HMM(A, B, observed, scaling_factors)\n",
    "        gamma = compute_all_conditional(alpha, beta, scaling_factors)\n",
    "        B = update_B(gamma, observed)\n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't multiply sequence by non-int of type 'numpy.float64'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Baum_Welch(A, B_start, pi, observed\u001b[39m=\u001b[39;49mviewed_chain, maxIter\u001b[39m=\u001b[39;49m\u001b[39m1000000\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[34], line 92\u001b[0m, in \u001b[0;36mBaum_Welch\u001b[0;34m(A, B_start, pi, observed, maxIter)\u001b[0m\n\u001b[1;32m     90\u001b[0m B \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mcopy(B_start)\n\u001b[1;32m     91\u001b[0m \u001b[39mfor\u001b[39;00m it \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(maxIter):\n\u001b[0;32m---> 92\u001b[0m     alpha, scaling_factors \u001b[39m=\u001b[39m forward_HMM(A, B, pi, observed)\n\u001b[1;32m     93\u001b[0m     beta \u001b[39m=\u001b[39m backward_HMM(A, B, observed, scaling_factors)\n\u001b[1;32m     94\u001b[0m     gamma \u001b[39m=\u001b[39m compute_all_conditional(alpha, beta, scaling_factors)\n",
      "Cell \u001b[0;32mIn[34], line 18\u001b[0m, in \u001b[0;36mforward_HMM\u001b[0;34m(A, B, pi, observed)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39m# Initialization\u001b[39;00m\n\u001b[1;32m     17\u001b[0m scaling_factors[\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m np\u001b[39m.\u001b[39msum(pi \u001b[39m*\u001b[39m B[:, observed[\u001b[39m0\u001b[39m]])\n\u001b[0;32m---> 18\u001b[0m alpha[\u001b[39m0\u001b[39m, :] \u001b[39m=\u001b[39m scaling_factors[\u001b[39m0\u001b[39;49m] \u001b[39m*\u001b[39;49m pi \u001b[39m*\u001b[39m B[:, observed[\u001b[39m0\u001b[39m]]\n\u001b[1;32m     20\u001b[0m \u001b[39m# Induction\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, n_nodes):\n",
      "\u001b[0;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'numpy.float64'"
     ]
    }
   ],
   "source": [
    "Baum_Welch(A, B_start, pi, observed=viewed_chain, maxIter=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
