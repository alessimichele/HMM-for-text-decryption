{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct(pmax, phi):\n",
    "    \"\"\"\n",
    "    Ricostruisce tutti i most probable, per ora fa schifo ma sembra funzionare, da ricontrollare\n",
    "    \"\"\"\n",
    "    reconstruction = np.empty(len(phi)+1)\n",
    "\n",
    "    curr = np.argmax(pmax[-1])\n",
    "    reconstruction[-1] = curr\n",
    "\n",
    "    for i in range(len(phi)-1, -1, -1):\n",
    "        curr = int(phi[i, curr])\n",
    "        reconstruction[i] = curr\n",
    "    \n",
    "    return reconstruction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiement with matrix like the one we have (last row of spaces has 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[0.1, 0.8, 0.1],\n",
    "              [0.8, 0.1, 0.1],\n",
    "              [0.5, 0.5, 0]])\n",
    "\n",
    "B = np.array([[0.8, 0.2, 0],\n",
    "              [0.2, 0.8, 0],\n",
    "              [0, 0, 1]])\n",
    "\n",
    "observed = np.array([0, 2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f(A, B, observed):\n",
    "    \"\"\"\n",
    "    Careful when handling\n",
    "    - f0 is the first message (from first factor to node, it is just a vector) \n",
    "    - f contains all other factors evaluated\n",
    "    \"\"\"\n",
    "    pi = A[-1]\n",
    "    n_nodes = len(observed)\n",
    "    n_states = A.shape[0]\n",
    "    f = np.zeros((n_nodes-1, n_states, n_states))\n",
    "    \n",
    "    tmp = np.zeros((n_states, 1))\n",
    "    for k in range(n_states):\n",
    "        tmp[k] = pi[k] * B[k, observed[0]]\n",
    "    \n",
    "    f0 = tmp\n",
    "\n",
    "    for i in range(1, n_nodes):\n",
    "        tmp = np.zeros((n_states, n_states))\n",
    "        \n",
    "        for j in range(n_states): # over z1\n",
    "            \n",
    "            for k in range(n_states): # over z2\n",
    "                tmp[j, k] = A[j, k] * B[k, observed[i]]\n",
    "        \n",
    "        f[i-1] = tmp\n",
    "    \n",
    "\n",
    "    return f0, f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f0:\n",
      " [[0.4]\n",
      " [0.1]\n",
      " [0. ]] \n",
      "f:\n",
      " [[[0.   0.   0.1 ]\n",
      "  [0.   0.   0.1 ]\n",
      "  [0.   0.   0.  ]]\n",
      "\n",
      " [[0.02 0.64 0.  ]\n",
      "  [0.16 0.08 0.  ]\n",
      "  [0.1  0.4  0.  ]]]\n"
     ]
    }
   ],
   "source": [
    "f0, f = compute_f(A, B, observed)\n",
    "print(\"f0:\\n\", f0, \"\\nf:\\n\", f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Viterbi(f0, f):\n",
    "    n_nodes = f.shape[0] + 1\n",
    "    n_states = f.shape[1]\n",
    "\n",
    "    pmax = np.zeros((n_nodes, n_states))    # Need one for every node\n",
    "    phi = np.zeros((n_nodes - 1, n_states)) # Need one for every node other than the first one (no need to reconstruct it)\n",
    "\n",
    "    pmax[0] = f0.flatten()\n",
    "\n",
    "    for i in range(1, n_nodes):\n",
    "        tmp = ((f[i-1]).T * pmax[i - 1]).T\n",
    "\n",
    "        pmax[i] = np.max(tmp, axis=0) # by column\n",
    "\n",
    "        phi[i-1] = np.argmax(tmp, axis=0) # i-1 cause this contains the reconstruction about the (i-1)th element\n",
    "\n",
    "    return pmax, phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pmax:\n",
      " [[0.4   0.1   0.   ]\n",
      " [0.    0.    0.04 ]\n",
      " [0.004 0.016 0.   ]] \n",
      "phi:\n",
      " [[0. 0. 0.]\n",
      " [2. 2. 0.]]\n",
      "\n",
      "Reconstruction using Viterbi:\n",
      " [0. 2. 1.]\n"
     ]
    }
   ],
   "source": [
    "pmax, phi = Viterbi(f0, f)\n",
    "print(\"pmax:\\n\", pmax, \"\\nphi:\\n\", phi)\n",
    "\n",
    "print(\"\\nReconstruction using Viterbi:\\n\", reconstruct(pmax, phi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pmax:\n",
      " [[4.00000000e-01 1.00000000e-01 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 4.00000000e-02]\n",
      " [4.00000000e-03 1.60000000e-02 0.00000000e+00]\n",
      " [1.02400000e-02 6.40000000e-04 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.02400000e-03]\n",
      " [4.09600000e-04 1.02400000e-04 0.00000000e+00]\n",
      " [1.63840000e-05 2.62144000e-04 0.00000000e+00]\n",
      " [1.67772160e-04 5.24288000e-06 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.67772160e-05]\n",
      " [1.67772160e-06 6.71088640e-06 0.00000000e+00]\n",
      " [4.29496730e-06 2.68435456e-07 0.00000000e+00]\n",
      " [8.58993459e-08 2.74877907e-06 0.00000000e+00]\n",
      " [1.75921860e-06 5.49755814e-08 0.00000000e+00]] \n",
      "phi:\n",
      " [[0. 0. 0.]\n",
      " [2. 2. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [2. 2. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 1. 0.]\n",
      " [0. 0. 0.]\n",
      " [2. 2. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [1. 1. 0.]]\n",
      "\n",
      "Reconstruction using Viterbi:\n",
      " [0. 2. 1. 0. 2. 0. 1. 0. 2. 1. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "observed = np.array([0, 2, 1, 0, 2, 0, 1, 0, 2, 1, 0, 1, 0]) # a _ b a\n",
    "f0, f = compute_f(A, B, observed)\n",
    "pmax, phi = Viterbi(f0, f)\n",
    "print(\"pmax:\\n\", pmax, \"\\nphi:\\n\", phi)\n",
    "\n",
    "print(\"\\nReconstruction using Viterbi:\\n\", reconstruct(pmax, phi))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log computations\n",
    "Now we need to find a way for this to hold even when working with logs.\n",
    "I suspect that replacing with the minimum to account for the 0 is too big, we need something smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[0.1, 0.8, 0.1],\n",
    "              [0.8, 0.1, 0.1],\n",
    "              [0.5, 0.5, 0]])\n",
    "\n",
    "B = np.array([[0.8, 0.2, 0],\n",
    "              [0.2, 0.8, 0],\n",
    "              [0, 0, 1]])\n",
    "\n",
    "observed = np.array([0, 2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f_log(A, B, observed):\n",
    "    \"\"\"\n",
    "    Even though it contains the -inf, this is fine, as that means we should not reconstruct using those (?)\n",
    "    \"\"\"\n",
    "    pi = A[-1]\n",
    "    n_nodes = len(observed)\n",
    "    n_states = A.shape[0]\n",
    "    f = np.zeros((n_nodes-1, n_states, n_states))\n",
    "    \n",
    "    tmp = np.zeros((n_states, 1))\n",
    "    for k in range(n_states):\n",
    "        tmp[k] = np.log(pi[k]) + np.log(B[k, observed[0]])\n",
    "    \n",
    "    f0 = tmp\n",
    "\n",
    "    for i in range(1, n_nodes):\n",
    "        tmp = np.zeros((n_states, n_states))\n",
    "        \n",
    "        for j in range(n_states): # over z1\n",
    "            \n",
    "            for k in range(n_states): # over z2\n",
    "                tmp[j, k] = np.log(A[j, k]) + np.log(B[k, observed[i]])\n",
    "    \n",
    "        f[i-1] = tmp\n",
    "    \n",
    "\n",
    "    return f0, f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Viterbi_log(f0, f):\n",
    "    n_nodes = f.shape[0] + 1\n",
    "    n_states = f.shape[1]\n",
    "\n",
    "    pmax = np.zeros((n_nodes, n_states))    # Need one for every node\n",
    "    phi = np.zeros((n_nodes - 1, n_states)) # Need one for every node other than the first one (no need to reconstruct it)\n",
    "\n",
    "    pmax[0] = f0.flatten()\n",
    "\n",
    "    for i in range(1, n_nodes):\n",
    "        tmp = ((f[i-1]).T + pmax[i - 1]).T\n",
    "\n",
    "        pmax[i] = np.max(tmp, axis=0) # by column\n",
    "\n",
    "        phi[i-1] = np.argmax(tmp, axis=0) # i-1 cause this contains the reconstruction about the (i-1)th element\n",
    "\n",
    "    return pmax, phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f0:\n",
      " [[-0.91629073]\n",
      " [-2.30258509]\n",
      " [       -inf]] \n",
      "f:\n",
      " [[[       -inf        -inf -2.30258509]\n",
      "  [       -inf        -inf -2.30258509]\n",
      "  [       -inf        -inf        -inf]]\n",
      "\n",
      " [[-3.91202301 -0.4462871         -inf]\n",
      "  [-1.83258146 -2.52572864        -inf]\n",
      "  [-2.30258509 -0.91629073        -inf]]]\n",
      "\n",
      "\n",
      "pmax:\n",
      " [[-0.91629073 -2.30258509        -inf]\n",
      " [       -inf        -inf -3.21887582]\n",
      " [-5.52146092 -4.13516656        -inf]] \n",
      "phi:\n",
      " [[0. 0. 0.]\n",
      " [2. 2. 0.]]\n",
      "\n",
      "\n",
      " reconstruction: [0. 2. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tv/ysw0jsvs2t331mtk7hdh35kc0000gn/T/ipykernel_63233/3658002382.py:12: RuntimeWarning: divide by zero encountered in log\n",
      "  tmp[k] = np.log(pi[k]) + np.log(B[k, observed[0]])\n",
      "/var/folders/tv/ysw0jsvs2t331mtk7hdh35kc0000gn/T/ipykernel_63233/3658002382.py:22: RuntimeWarning: divide by zero encountered in log\n",
      "  tmp[j, k] = np.log(A[j, k]) + np.log(B[k, observed[i]])\n"
     ]
    }
   ],
   "source": [
    "f0, f = compute_f_log(A, B, observed)\n",
    "print(\"f0:\\n\", f0, \"\\nf:\\n\", f)\n",
    "\n",
    "\n",
    "pmax, phi = Viterbi_log(f0, f)\n",
    "print(\"\\n\\npmax:\\n\", pmax, \"\\nphi:\\n\", phi)\n",
    "\n",
    "print(\"\\n\\n reconstruction:\", reconstruct(pmax, phi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f0:\n",
      " [[-0.91629073]\n",
      " [-2.30258509]\n",
      " [       -inf]] \n",
      "f:\n",
      " [[[       -inf        -inf -2.30258509]\n",
      "  [       -inf        -inf -2.30258509]\n",
      "  [       -inf        -inf        -inf]]\n",
      "\n",
      " [[-3.91202301 -0.4462871         -inf]\n",
      "  [-1.83258146 -2.52572864        -inf]\n",
      "  [-2.30258509 -0.91629073        -inf]]\n",
      "\n",
      " [[       -inf        -inf -2.30258509]\n",
      "  [       -inf        -inf -2.30258509]\n",
      "  [       -inf        -inf        -inf]]\n",
      "\n",
      " [[-3.91202301 -0.4462871         -inf]\n",
      "  [-1.83258146 -2.52572864        -inf]\n",
      "  [-2.30258509 -0.91629073        -inf]]\n",
      "\n",
      " [[-2.52572864 -1.83258146        -inf]\n",
      "  [-0.4462871  -3.91202301        -inf]\n",
      "  [-0.91629073 -2.30258509        -inf]]\n",
      "\n",
      " [[-3.91202301 -0.4462871         -inf]\n",
      "  [-1.83258146 -2.52572864        -inf]\n",
      "  [-2.30258509 -0.91629073        -inf]]]\n",
      "\n",
      "\n",
      "pmax:\n",
      " [[ -0.91629073  -2.30258509         -inf]\n",
      " [        -inf         -inf  -3.21887582]\n",
      " [ -5.52146092  -4.13516656         -inf]\n",
      " [        -inf         -inf  -6.43775165]\n",
      " [ -8.74033674  -7.35404238         -inf]\n",
      " [ -7.80032948 -10.57291821         -inf]\n",
      " [-11.71235249  -8.24661659         -inf]] \n",
      "phi:\n",
      " [[0. 0. 0.]\n",
      " [2. 2. 0.]\n",
      " [0. 0. 1.]\n",
      " [2. 2. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "\n",
      "\n",
      " reconstruction: [0. 2. 1. 2. 1. 0. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tv/ysw0jsvs2t331mtk7hdh35kc0000gn/T/ipykernel_63233/3658002382.py:12: RuntimeWarning: divide by zero encountered in log\n",
      "  tmp[k] = np.log(pi[k]) + np.log(B[k, observed[0]])\n",
      "/var/folders/tv/ysw0jsvs2t331mtk7hdh35kc0000gn/T/ipykernel_63233/3658002382.py:22: RuntimeWarning: divide by zero encountered in log\n",
      "  tmp[j, k] = np.log(A[j, k]) + np.log(B[k, observed[i]])\n"
     ]
    }
   ],
   "source": [
    "observed = np.array([0, 2, 1, 2, 1, 0, 1]) # a = 0; b = 1; _ = 2\n",
    "f0, f = compute_f_log(A, B, observed)\n",
    "print(\"f0:\\n\", f0, \"\\nf:\\n\", f)\n",
    "\n",
    "\n",
    "pmax, phi = Viterbi_log(f0, f)\n",
    "print(\"\\n\\npmax:\\n\", pmax, \"\\nphi:\\n\", phi)\n",
    "\n",
    "print(\"\\n\\n reconstruction:\", reconstruct(pmax, phi))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try using our words example\n",
    "Now using the matrix and our phrase we try and see if it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.CipherUtils import CipherGenerator\n",
    "from src.CipherUtils import TextEncoder\n",
    "from src.ProbabilityMatrix import ProbabilityMatrix\n",
    "from src.CipherUtils import TextPreProcessor\n",
    "\n",
    "from src.HMM_utils import map_alphabet_to_numbers, string_to_numbers\n",
    "from src.HMM_utils import find_mapping, numbers_to_string, invert_mapping\n",
    "\n",
    "from src.HMM_functions import Baum_Welch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in germany it seems to be pretty much automatic pretty much all the time in france and spain it all just depends presumably on social subtleties that you have to be french or spanish to understand in italy why would you even just bother when and how much to tip is a question that has been vexing visitors to europe for as long as people have been travelling around the continent outside their own country it seems even europeans don t know the answer according to new polling by yougov in six eu countries britain and the us where as most visitors know but may be reluctant to acknowledge gratuities may make up more than half your waitperson s income europeans are deeply divided on tipping in restaurants for example of respondents in germany told the pollster they typically tipped almost the same as the us in the uk where an optional service charge of about is usually included said they left a gratuity the figure in spain where service is often included in restaurant bills but diners can leave optional tips was while in france where every price on a restaurant menu already includes for service of people said they generally tipped on top even in sweden where tips are generally not expected the figure was but only of italians said they would typically leave a gratuity after a meal out with a rather greater proportion admitting they never left a cent a startling of respondents in the us however and of germans by far the most in europe confessed they would tip sometimes or often even if the service was terrible indicating that for some tipping is not about quality of service at all the findings of the survey will come as a surprise in germany a country that does not generally think of itself as a nation of happy distributors\n",
      "dl otupclb de fttpf ei yt quteeb pwxj cweipcedx quteeb pwxj caa ejt edpt dl kuclxt clh fqcdl de caa nwfe htqtlhf qutfwpcyab il fixdca fwyeatedtf ejce biw jcst ei yt kutlxj iu fqcldfj ei wlhtufeclh dl decab gjb giwah biw tstl nwfe yiejtu gjtl clh jig pwxj ei edq df c mwtfedil ejce jcf yttl stzdlo sdfdeiuf ei twuiqt kiu cf ailo cf qtiqat jcst yttl eucstaadlo cuiwlh ejt xiledltle iwefdht ejtdu igl xiwleub de fttpf tstl twuiqtclf hil e rlig ejt clfgtu cxxiuhdlo ei ltg qiaadlo yb biwois dl fdz tw xiwleudtf yudecdl clh ejt wf gjtut cf pife sdfdeiuf rlig ywe pcb yt utawxecle ei cxrligathot oucewdedtf pcb pcrt wq piut ejcl jcak biwu gcdeqtufil f dlxipt twuiqtclf cut httqab hdsdhth il edqqdlo dl utfecwuclef kiu tzcpqat ik utfqilhtlef dl otupclb eiah ejt qiaafetu ejtb ebqdxcaab edqqth capife ejt fcpt cf ejt wf dl ejt wr gjtut cl iqedilca ftusdxt xjcuot ik cyiwe df wfwcaab dlxawhth fcdh ejtb atke c oucewdeb ejt kdowut dl fqcdl gjtut ftusdxt df iketl dlxawhth dl utfecwucle ydaaf ywe hdltuf xcl atcst iqedilca edqf gcf gjdat dl kuclxt gjtut tstub qudxt il c utfecwucle ptlw cautchb dlxawhtf kiu ftusdxt ik qtiqat fcdh ejtb otltucaab edqqth il eiq tstl dl fgthtl gjtut edqf cut otltucaab lie tzqtxeth ejt kdowut gcf ywe ilab ik decadclf fcdh ejtb giwah ebqdxcaab atcst c oucewdeb cketu c ptca iwe gdej c ucejtu outcetu quiqiuedil chpdeedlo ejtb ltstu atke c xtle c fecueadlo ik utfqilhtlef dl ejt wf jigtstu clh ik otupclf yb kcu ejt pife dl twuiqt xilktffth ejtb giwah edq fiptedptf iu iketl tstl dk ejt ftusdxt gcf etuudyat dlhdxcedlo ejce kiu fipt edqqdlo df lie cyiwe mwcadeb ik ftusdxt ce caa ejt kdlhdlof ik ejt fwustb gdaa xipt cf c fwuqudft dl otupclb c xiwleub ejce hitf lie otltucaab ejdlr ik deftak cf c lcedil ik jcqqb hdfeudyweiuf\n"
     ]
    }
   ],
   "source": [
    "#hidden_sequence = \"people of western europe a landing was made this morning on the coast of france by troops kangaroo jokes quasi vile xilophone zenit \"\n",
    "hidden_sequence = \"in germany it seems to be pretty much automatic pretty much all the time in france and spain it all just depends presumably on social subtleties that you have to be french or spanish to understand in italy why would you even just bother when and how much to tip is a question that has been vexing visitors to europe for as long as people have been travelling around the continent outside their own country it seems even europeans don t know the answer according to new polling by yougov in six eu countries britain and the us where as most visitors know but may be reluctant to acknowledge gratuities may make up more than half your waitperson s income europeans are deeply divided on tipping in restaurants for example of respondents in germany told the pollster they typically tipped almost the same as the us in the uk where an optional service charge of about is usually included said they left a gratuity the figure in spain where service is often included in restaurant bills but diners can leave optional tips was while in france where every price on a restaurant menu already includes for service of people said they generally tipped on top even in sweden where tips are generally not expected the figure was but only of italians said they would typically leave a gratuity after a meal out with a rather greater proportion admitting they never left a cent a startling of respondents in the us however and of germans by far the most in europe confessed they would tip sometimes or often even if the service was terrible indicating that for some tipping is not about quality of service at all the findings of the survey will come as a surprise in germany a country that does not generally think of itself as a nation of happy distributors\"\n",
    "# hidden_sequence = \"hello banana xilophone key queue zebra cock pussy tits dandy fart though jolly world mum \"\n",
    "\n",
    "cipher_generator = CipherGenerator()\n",
    "cipher = cipher_generator.generate_cipher()\n",
    "encoder = TextEncoder()\n",
    "observed_sequence = encoder.encode_text(hidden_sequence, cipher=cipher)\n",
    "\n",
    "# Convert to numeric\n",
    "hidden_ = string_to_numbers(hidden_sequence, mapping=map_alphabet_to_numbers())\n",
    "observed_ = string_to_numbers(observed_sequence, mapping=map_alphabet_to_numbers())\n",
    "\n",
    "print(hidden_sequence)\n",
    "print(observed_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of text file paths to build our corpus (where we learn the transitions probs)\n",
    "file_paths = [\n",
    "    \"texts/moby_dick.txt\",\n",
    "    \"texts/shakespeare.txt\",\n",
    "    \"texts/james-joyce-a-portrait-of-the-artist-as-a-young-man.txt\",\n",
    "    \"texts/james-joyce-dubliners.txt\",\n",
    "    \"texts/james-joyce-ulysses.txt\",\n",
    "]\n",
    "\n",
    "texts = []\n",
    "for file_path in file_paths:\n",
    "    with open(file_path, \"r\") as file:\n",
    "        texts.append(file.read())\n",
    "\n",
    "corpus = \"\".join(texts)\n",
    "alphabet = list(\"abcdefghijklmnopqrstuvwxyz \")\n",
    "\n",
    "preprocessor = TextPreProcessor()\n",
    "corpus = preprocessor.lower(text=corpus)\n",
    "corpus = preprocessor.remove_additional_spaces(text=corpus)\n",
    "corpus = preprocessor.remove_unknown_chars(\n",
    "    text=corpus, unknown_chars=preprocessor.unknown_chars(corpus)\n",
    ")\n",
    "\n",
    "# compute probabilities\n",
    "p = ProbabilityMatrix(corpus)\n",
    "p.compute_probability_matrix()\n",
    "p.compute_normalized_matrix()\n",
    "# p.compute_probability_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_start = np.zeros((27, 27)) + 1 / 26\n",
    "B_start[:, -1] = np.zeros(27)\n",
    "B_start[-1, :] = np.zeros(27)\n",
    "B_start[-1, -1] = 1\n",
    "\n",
    "emission = Baum_Welch(\n",
    "    A=p.normalized_matrix,\n",
    "    B_start=B_start,\n",
    "    pi=p.normalized_matrix[-1, :],\n",
    "    observed=observed_,\n",
    "    maxIter=50,\n",
    ")\n",
    "mapping = find_mapping(emission.argmax(axis=1))\n",
    "normalized_emission_reconstruction = numbers_to_string(observed_sequence, invert_mapping(mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_start = np.zeros((27, 27)) + 1 / 26\n",
    "B_start[:, -1] = np.zeros(27)\n",
    "B_start[-1, :] = np.zeros(27)\n",
    "B_start[-1, -1] = 1\n",
    "\n",
    "emission_non_norm = Baum_Welch(\n",
    "    A=p.probability_matrix,\n",
    "    B_start=B_start,\n",
    "    pi=p.probability_matrix[-1, :],\n",
    "    observed=observed_,\n",
    "    maxIter=50,\n",
    ")\n",
    "mapping_non_norm = find_mapping(emission_non_norm.argmax(axis=1))\n",
    "non_normalized_emission_reconstruction = numbers_to_string(observed_sequence, invert_mapping(mapping_non_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tv/ysw0jsvs2t331mtk7hdh35kc0000gn/T/ipykernel_63233/3658002382.py:12: RuntimeWarning: divide by zero encountered in log\n",
      "  tmp[k] = np.log(pi[k]) + np.log(B[k, observed[0]])\n",
      "/var/folders/tv/ysw0jsvs2t331mtk7hdh35kc0000gn/T/ipykernel_63233/3658002382.py:22: RuntimeWarning: divide by zero encountered in log\n",
      "  tmp[j, k] = np.log(A[j, k]) + np.log(B[k, observed[i]])\n"
     ]
    }
   ],
   "source": [
    "f0, f = compute_f_log(A = p.normalized_matrix, B=emission, observed=observed_)\n",
    "pmax, phi = Viterbi_log(f0, f)\n",
    "reconstruction = reconstruct(pmax, phi)\n",
    "reconstruction = reconstruction.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tv/ysw0jsvs2t331mtk7hdh35kc0000gn/T/ipykernel_63233/3658002382.py:12: RuntimeWarning: divide by zero encountered in log\n",
      "  tmp[k] = np.log(pi[k]) + np.log(B[k, observed[0]])\n",
      "/var/folders/tv/ysw0jsvs2t331mtk7hdh35kc0000gn/T/ipykernel_63233/3658002382.py:22: RuntimeWarning: divide by zero encountered in log\n",
      "  tmp[j, k] = np.log(A[j, k]) + np.log(B[k, observed[i]])\n"
     ]
    }
   ],
   "source": [
    "f0, f = compute_f_log(A = p.probability_matrix, B=emission_non_norm, observed=observed_)\n",
    "pmax, phi = Viterbi_log(f0, f)\n",
    "reconstruction_non_norm = reconstruct(pmax, phi)\n",
    "reconstruction_non_norm = reconstruction_non_norm.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def convert_numbers_to_letters(numbers):\n",
    "    letters = []\n",
    "    for number in numbers:\n",
    "        if number == 26:\n",
    "            letters.append(' ')\n",
    "        else:\n",
    "            letter = chr(number + ord('a'))\n",
    "            letters.append(letter)\n",
    "    return ''.join(letters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-normalized emission reconstruction:\n",
      " in permany it seems to be qretty muzh automatiz qretty muzh all the time in franze and sqain it all qust deqends qresumably on sozial subtleties that you have to be frenzh or sqanish to understand in italy why would you even qust bother when and how muzh to tiq is a muestion that has been vexinp visitors to euroqe for as lonp as qeoqle have been travellinp around the zontinent outside their own zountry it seems even euroqeans don t rnow the answer azzordinp to new qollinp by youpov in six eu zountries britain and the us where as most visitors rnow but may be reluztant to azrnowledpe pratuities may mare uq more than half your waitqerson s inzome euroqeans are deeqly divided on tiqqinp in restaurants for examqle of resqondents in permany told the qollster they tyqizally tiqqed almost the same as the us in the ur where an oqtional servize zharpe of about is usually inzluded said they left a pratuity the fipure in sqain where servize is often inzluded in restaurant bills but diners zan leave oqtional tiqs was while in franze where every qrize on a restaurant menu already inzludes for servize of qeoqle said they penerally tiqqed on toq even in sweden where tiqs are penerally not exqezted the fipure was but only of italians said they would tyqizally leave a pratuity after a meal out with a rather preater qroqortion admittinp they never left a zent a startlinp of resqondents in the us however and of permans by far the most in euroqe zonfessed they would tiq sometimes or often even if the servize was terrible indizatinp that for some tiqqinp is not about muality of servize at all the findinps of the survey will zome as a surqrise in permany a zountry that does not penerally thinr of itself as a nation of haqqy distributors\n",
      "Non-normalized reconstruction:\n",
      " in permane it seers to be thethe muth automatit thethe muth all the time in france and sthin it all bust derends thesumably on sothal susthethes that you have to be french or stanish to anderstand in italy whe would you eren bust bother when and how muth to tit is a thestion that has been verind wisitors to ourore for as lond as teathe have been thavellind around the continent outhide their own counthe it seers eren ouroreans don t anow the anster accordind to net tollind be yougor in sis ou counthies brithin and the us where as most wisitors anow but may be heluthant to acanowhedge prathithes may mare at more than half your waitherson s income ouroreans are deethe divided on tithind in hestherants for erample of hestondents in permane told the tollster they terically tithed allost the same as the us in the ad where an othional serkice tharde of about is useally incheded said they lest a prathite the figure in sthin where serkice is often incheded in hestherant bills but diners can leave othional tits was while in france where erere thice on a hestherant mene alleade inchedes for serkice of teathe said they penerally tithed on tot eren in steden where tits are penerally not esteched the figure was but only of italians said they would terically leave a prathite aster a meal out with a hather preater thotortion admithind they nerer lest a cent a starthind of hestondents in the us howerer and of permans be far the most in ourore consessed they would tit sometimes or often eren is the serkice was terrible indicatind that for some tithind is not about thalite of serkice at all the findings of the survey will come as a surthise in permane a counthe that does not penerally thind of ithelf as a nation of hathe disthibutors\n",
      "\n",
      "\n",
      "Normalized emission reconstruction:\n",
      " in oqrmany it sqqms to bq prqtty muzh automatiz prqtty muzh all thq timq in franzq and spain it all nust dqpqnds prqsumably on sozial subtlqtiqs that you havq to bq frqnzh or spanish to undqrstand in italy why would you qvqn nust bothqr whqn and how muzh to tip is a muqstion that has bqqn vqxino visitors to quropq for as lono as pqoplq havq bqqn travqllino around thq zontinqnt outsidq thqir own zountry it sqqms qvqn quropqans don t know thq answqr azzordino to nqw pollino by youoov in six qu zountriqs britain and thq us whqrq as most visitors know but may bq rqluztant to azknowlqdoq oratuitiqs may makq up morq than half your waitpqrson s inzomq quropqans arq dqqply dividqd on tippino in rqstaurants for qxamplq of rqspondqnts in oqrmany told thq pollstqr thqy typizally tippqd almost thq samq as thq us in thq uk whqrq an optional sqrvizq zharoq of about is usually inzludqd said thqy lqft a oratuity thq fiourq in spain whqrq sqrvizq is oftqn inzludqd in rqstaurant bills but dinqrs zan lqavq optional tips was whilq in franzq whqrq qvqry prizq on a rqstaurant mqnu alrqady inzludqs for sqrvizq of pqoplq said thqy oqnqrally tippqd on top qvqn in swqdqn whqrq tips arq oqnqrally not qxpqztqd thq fiourq was but only of italians said thqy would typizally lqavq a oratuity aftqr a mqal out with a rathqr orqatqr proportion admittino thqy nqvqr lqft a zqnt a startlino of rqspondqnts in thq us howqvqr and of oqrmans by far thq most in quropq zonfqssqd thqy would tip somqtimqs or oftqn qvqn if thq sqrvizq was tqrriblq indizatino that for somq tippino is not about muality of sqrvizq at all thq findinos of thq survqy will zomq as a surprisq in oqrmany a zountry that doqs not oqnqrally think of itsqlf as a nation of happy distributors\n",
      "Normalized reconstruction:\n",
      " in bermand it seems to be prethy much automatig prethy much all the time in france and spain it all qust depends presumably on sochal sucthethes that you have to be french or spanish to understand in italy why would you even qust bother when and how much to tis is a question that has been vexing visitors to qurome for as long as pexple have been thavelling around the continent outhide their own coungry it seems even quromeans don t know the answer according to new polling by yougok in sis qu coungries britain and the us where as most visitors know but may be reluchant to acknowhedge brathithes may make up more than half your waitherson s income quromeans are deeply divided on tipping in restourants for example of respondents in bermand told the pollster they typically tipped almost the same as the us in the uk where an outional service charge of about is ushally included said they left a brathity the figure in spain where service is often included in restourant bills but diners can leave outional tiss was while in france where every price on a restourant mend alleady includes for service of pexple said they benerally tipped on tom even in sweden where tiss are benerally not expected the figure was but only of italians said they would typically leave a brathity anter a meal out with a rather breater proportion ammithing they never left a cent a starthing of respondents in the us however and of bermans by far the most in qurome coffessed they would tis sometimes or often even if the service was terrible indicating that for some tipping is not about quality of service at all the findings of the survey will come as a surprise in bermand a coungry that does not benerally think of ithelf as a fation of happy disthibutors\n"
     ]
    }
   ],
   "source": [
    "normalized_reconstruction = convert_numbers_to_letters(reconstruction)\n",
    "non_normalized_reconstruction = convert_numbers_to_letters(reconstruction_non_norm)\n",
    "\n",
    "print(\"Non-normalized emission reconstruction:\\n\", non_normalized_emission_reconstruction)\n",
    "print(\"Non-normalized reconstruction:\\n\", non_normalized_reconstruction)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Normalized emission reconstruction:\\n\", normalized_emission_reconstruction)\n",
    "print(\"Normalized reconstruction:\\n\", normalized_reconstruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in bermand it seems to be prethy much automatig prethy much all the time in france and spain it all qust depends presumably on sochal sucthethes that you have to be french or spanish to understand in italy why would you even qust bother when and how much to tis is a question that has been vexing visitors to qurome for as long as pexple have been thavelling around the continent outhide their own coungry it seems even quromeans don t know the answer according to new polling by yougok in sis qu coungries britain and the us where as most visitors know but may be reluchant to acknowhedge brathithes may make up more than half your waitherson s income quromeans are deeply divided on tipping in restourants for example of respondents in bermand told the pollster they typically tipped almost the same as the us in the uk where an outional service charge of about is ushally included said they left a brathity the figure in spain where service is often included in restourant bills but diners can leave outional tiss was while in france where every price on a restourant mend alleady includes for service of pexple said they benerally tipped on tom even in sweden where tiss are benerally not expected the figure was but only of italians said they would typically leave a brathity anter a meal out with a rather breater proportion ammithing they never left a cent a starthing of respondents in the us however and of bermans by far the most in qurome coffessed they would tis sometimes or often even if the service was terrible indicating that for some tipping is not about quality of service at all the findings of the survey will come as a surprise in bermand a coungry that does not benerally think of ithelf as a fation of happy disthibutors\n",
      "in germany it seems to be pretty much automatic pretty much all the time in france and spain it all just depends presumably on social subtleties that you have to be french or spanish to understand in italy why would you even just bother when and how much to tip is a question that has been vexing visitors to europe for as long as people have been travelling around the continent outside their own country it seems even europeans don t know the answer according to new polling by yougov in six eu countries britain and the us where as most visitors know but may be reluctant to acknowledge gratuities may make up more than half your waitperson s income europeans are deeply divided on tipping in restaurants for example of respondents in germany told the pollster they typically tipped almost the same as the us in the uk where an optional service charge of about is usually included said they left a gratuity the figure in spain where service is often included in restaurant bills but diners can leave optional tips was while in france where every price on a restaurant menu already includes for service of people said they generally tipped on top even in sweden where tips are generally not expected the figure was but only of italians said they would typically leave a gratuity after a meal out with a rather greater proportion admitting they never left a cent a startling of respondents in the us however and of germans by far the most in europe confessed they would tip sometimes or often even if the service was terrible indicating that for some tipping is not about quality of service at all the findings of the survey will come as a surprise in germany a country that does not generally think of itself as a nation of happy distributors\n"
     ]
    }
   ],
   "source": [
    "print(normalized_reconstruction)\n",
    "print(hidden_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized emission accuracy: 0.8577981651376146\n",
      "normalized reconstruction accuracy: 0.9604357798165137\n",
      "NON normalized emission accuracy: 0.9317660550458715\n",
      "NON normalized reconstruction accuracy: 0.8830275229357798\n"
     ]
    }
   ],
   "source": [
    "print(\"normalized emission accuracy:\", np.mean(np.array(list(normalized_emission_reconstruction)) == np.array(list(hidden_sequence))))\n",
    "print(\"normalized reconstruction accuracy:\", np.mean(np.array(list(normalized_reconstruction)) == np.array(list(hidden_sequence))))\n",
    "\n",
    "print(\"NON normalized emission accuracy:\", np.mean(np.array(list(non_normalized_emission_reconstruction)) == np.array(list(hidden_sequence))))\n",
    "print(\"NON normalized reconstruction accuracy:\", np.mean(np.array(list(non_normalized_reconstruction)) == np.array(list(hidden_sequence))))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
